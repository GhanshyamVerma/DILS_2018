%\documentclass[12pt]{article}
\documentclass[a4paper, 10pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[backend=bibtex, sorting=none]{biblatex}
\bibliography{references}

% Preamble:
\addtolength{\oddsidemargin}{-.875in}
	\addtolength{\evensidemargin}{-.875in}
	\addtolength{\textwidth}{1.75in}

	\addtolength{\topmargin}{-.875in}
	\addtolength{\textheight}{1.75in}
\title{\bf \bf Respiratory Viral Data Set: SVM on 64 Subjects Data using 0 and Onset Time}
\author{Ghanshyam Verma}
\date{}

% add references here
\begin{filecontents*}{references.bib}


\end{filecontents*}
% Document:
\begin{document}
% 
% mean(1:10)
% plot(1:10)
\maketitle
%\tableofcontents

\section{About the Respiratory Viral Data Set}
The respiratory viral challenge study consists of a total of 151 human volunteers (subjects). All the subjects after enrolment in the study, were inoculated with virus from one of the 4 categories of pathogen (H1N1, H3N2, HRV, RSV). The overall study was conducted in 7 stages (see Table 1 for a summary).


\begin{table}[]
\centering
\caption{The details of the data collected in the respiratory virus challenge study. The first column is the sub-study designation. Second column is the virus used in the challenge. Third and fourth columns are the year and location the sub-study was conducted. Fifth column is the DUHS IRB protocol number. Sixth column is the duration of the sub-study in hours. Last two columns are the number of subjects and the number of time points collected per subject, respectively}
\label{my-label}
\begin{tabular}{llllllll}
\hline
Challenge & Virus & Year & Location          & IRB protocol & Duration (hrs) & \# Subjects & \# Time points \\ \hline
DEE1      & RSV   & 2008 & Retroscreen       & Pro00002796  & 166            & 20          & 21             \\
DEE2      & H3N2  & 2009 & Retroscreen       & Pro00006750  & 166            & 17          & 21             \\
DEE3      & H1N1  & 2009 & Retroscreen       & Pro00018132  & 166            & 24          & 20             \\
DEE4      & H1N1  & 2010 & Retroscreen       & Pro00019238  & 166            & 19          & 21             \\
DEE5      & H3N2  & 2011 & Retroscreen       & Pro00029521  & 680            & 21          & 23             \\
HRV UVA   & HRV   & 2008 & Univ. of Virginia & Pro00003477  & 120            & 20          & 15             \\
HRV Duke  & HRV   & 2010 & Duke Univ.        & Pro00022448  & 136            & 30          & 19            
\end{tabular}
\end{table}


\section{Ambiguous Subjects}
Out of these 151 subjects, 47 subjects have been excluded. Among those 47 subjects, 44 subjects excluded due to inconsistencies between their declared symptomatic status and measured shedding status. These 44 clinically ambiguous subjects were at some time either acutely infected but asymptomatic or not infected but acutely symptomatic (See table 2 for more details). Three subjects excluded because there were no affymatrix gene probes collected (HRV DUKE subject ID 6, 19 and 21). 


\begin{table}[]
\centering
\caption{Detail of the ambiguous subjects}
\label{my-label}
\begin{tabular}{llll}
\hline
\textbf{Sr. No.} & \textbf{Study ID} & \textbf{Subject ID (Ambiguous Subjects)}  & \textbf{Total} \\ \hline
1                & RSV DEE 1         & 13, 15, 16                                & 3              \\
2                & H3N2 DEE 2        & 2, 4                                      & 2              \\
3                & H1N1 DEE3         & 1, 2, 5, 7, 11, 15, 18, 21, 23            & 9              \\
4                & H1N1 DEE4         & 5, 7, 8, 9, 10, 11, 12, 13, 17, 19        & 10             \\
5                & H3N2 DEE5         & 3, 7, 15, 16, 17                          & 5              \\
6                & HRV UVA           & 1, 10, 12, 17                             & 4              \\
7                & HRV DUKE          & 3, 10, 11, 15, 18, 20, 25, 27, 28, 29, 30 & 11             \\
                 &                   &                                           & \textbf{44}   
\end{tabular}
\end{table}


\section{SVM Classifier on All 7 Challenge Studies Data 2 Specific Time Points}
For this report, I have taken 64 infected subjects into consideration. I have extracted 2 time-specific data points for each infected and unambiguous subject of these challenge studies. For each infected subject, the first sample is the sample taken before inoculation (at 0 hour) i.e. having label “not infected” or “negative” and the second sample is the sample which is near the Onset Time i.e. having label “infected” or “positive”. \\
Onset time is the time when a subject starts showing symptoms of infection and in our case, it is different for most of the subjects. We don't have gene expression data on exact Onset time points for every subject, therefore, gene expression data near to the Onset time has been taken for the analysis. Only one subject's sample has been taken just before Onset time rest all the samples are either just after the onset time or at exact onset time. This is because that one subject neither has data after Onset Time nor at Onset Time. \\

This is an experiment to predict the state of infection that involves analysis of the gene expression profile of subjects for only 2 time points i.e. before inoculation and after inoculation. Therefore, it is a binary class classification problem having two classes. To make it easier, I have labeled “not infected” subjects as “negative” and “infected” subjects as “positive”. I have applied Linear SVM and Non-Linear SVM classification algorithm on above explained data set. 

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
## Loading data set 
#Libraries 
library(class)
library(caret)
library(dplyr) # For efficient access of dataframes 
library(pROC) # For Plotting the ROC curves
library(ggplot2)

# Set working directory
getwd()
setwd("/Users/ghanshyamverma/Documents/Respiratory_Data/The_64_Subjects_Results/SVM")
@


<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Read the labeled gene expression data
# Read the labeled gene expression data
Data_64_Subjects_0_Onset_Time <- read.csv("Data_64_Subjects_0_Onset_Time.csv", 
                                      header = TRUE, sep = ",")

# Display the data
Data_64_Subjects_0_Onset_Time[c(1:7),c(1:7)] # show first 7 rows

# Display the dimensions (rows columns)
(dim(Data_64_Subjects_0_Onset_Time))

@
\section{Data Partitioning into Training and Test Set}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
## Dividing data set into train (78%) and test (22%) using createDataPartition function of caret package
set.seed(1234)
index_Train <- createDataPartition(y = Data_64_Subjects_0_Onset_Time$Label, p = 0.78, list = 
                                      FALSE)
g_train_data <- Data_64_Subjects_0_Onset_Time[index_Train, ]
g_test_data <- Data_64_Subjects_0_Onset_Time[-index_Train, ]

# Display the dimensions (rows columns)
(dim(g_train_data))
(dim(g_test_data))

# Converting class labels into categorical variable
g_train_data[["Label"]] = factor(g_train_data[["Label"]])

@
\section{Linear SVM model}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Enable Parallel Processing
library(doSNOW)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoSNOW(cl)
pt<-proc.time()

set.seed(1234)
(cross_validation_10_fold <- trainControl(method = "repeatedcv", # apply repeated CV
                                         number = 10, # 10 fold cv 
                                         repeats = 3))  # 3 repititions of CV
                                         
set.seed(1234)
(svm_train <- train(Label~., # Class labels of training data
                   data = g_train_data,  # Training Data
                   method = "svmLinear", # Train using linear kernel
                   trControl = cross_validation_10_fold))

# Stop Parallel Processing
proc.time()-pt
stopCluster(cl)
@

\subsection{Linear SVM: Test Set Prediction}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Predicting Test Set 
# Passing test data without labels (without fist column which contains labels)
(testPrediction <- predict(svm_train, newdata = g_test_data[,2:12024]))

# Test data set
(g_test_data$Label)
@

\subsection{Linear SVM: Performance Measure}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Display confusion matrix
(confusionMatrix(testPrediction, g_test_data$Label))

@

\subsection{Linear SVM: Tune Linear SVM Parameters}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Enable Parallel Processing
library(doSNOW)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoSNOW(cl)
pt<-proc.time()

# Assigning values to the parameter C
(grid <- expand.grid(C = c(2^-5, 2^-3, 2^-1, 1, 2^1, 3, 5, 2^3, 2^5,
                          2^7, 2^9, 2^11, 2^13, 2^15)))

set.seed(1234)
(svm_train_linear_tuned <- train(Label~., # Class labels of training data
                                data = g_train_data,  # Training Data
                                method = "svmLinear", # Train using linear kernel
                                tuneGrid = grid, # Passing grid for tuning
                                trControl = cross_validation_10_fold)) # Cross validation setting

# Stop Parallel Processing
proc.time()-pt
stopCluster(cl)

# Plot tuned linear svm (Trained Model)
plot(svm_train_linear_tuned)
@ 

\subsection{Linear SVM: Test Set Prediction using Tuned Linear SVM}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Predicting Test Set 
# Passing test data without labels (without fist column which contains labels)
(testPrediction_tuned_L_SVM <- predict(svm_train_linear_tuned, newdata = g_test_data[,2:12024]))

# Test data set
(g_test_data$Label)
@

\subsection{Linear SVM: Performance Measure using Tuned Linear SVM}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Display confusion matrix
(confusionMatrix(testPrediction_tuned_L_SVM, g_test_data$Label))

@

\subsection{Tune Non-Linear SVM (with RBF Kernel) Parameters}
<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Enable Parallel Processing
library(doSNOW)
library(doParallel)
cl <- makeCluster(detectCores())
registerDoSNOW(cl)
pt<-proc.time()

# Assigning values to the parameter C
gridRBF <- expand.grid(sigma = c(2^-25, 2^-23, 2^-21, 2^-19, 2^-17,2^-15, 
                                 2^-13, 2^-11, 2^-9, 2^-7, 2^-5, 2^-3, 
                                 2^-1, 1, 2^1, 3, 5, 2^3),
                           C = c(2^-5, 2^-3, 2^-1, 1, 2^1, 3, 5, 2^3, 2^5,
                                 2^7, 2^9, 2^11, 2^13, 2^15))

set.seed(1234)
(svm_train_RBF_tuned <- train(Label~., # Class labels of training data
                                data = g_train_data,  # Training Data
                                method = "svmRadial", # Train using linear kernel
                                #preProcess = "range", # range between 0 to 1
                                tuneGrid = gridRBF, # Use RBF kernel 
                                trControl = cross_validation_10_fold)) # Passing cross validation values

# Stop Parallel Processing
proc.time()-pt
stopCluster(cl)

# Plot tuned linear svm (Trained Model)
plot(svm_train_RBF_tuned)
@ 

\subsection{Non-Linear SVM: Test Set Prediction using Tuned RBF SVM}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Predicting Test Set 
# Passing test data without labels (without fist column which contains labels)
(testPrediction_tuned_RBF_SVM <- predict(svm_train_RBF_tuned, newdata = g_test_data[,2:12024]))

# Test data set
(g_test_data$Label)
@

\subsection{Non-Linear SVM: Performance Measure using Tuned RBF SVM}

<<include=TRUE, message=FALSE, warning=FALSE, error=FALSE>>=
# Display confusion matrix
(confusionMatrix(testPrediction_tuned_RBF_SVM, g_test_data$Label))

@


\end{document} 